{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MajorFeijo/RNA-e-Deep-Learning-CESAR-School-2023.02/blob/main/Trabalho%20Final/Projeto_Final_da_Disciplinal_FashionMNIST_neuralnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Equipe:\n",
        "* Armando Feijó de Paula - afp2@cesar.school\n",
        "\n",
        "## Data sete escolhido:\n",
        "* https://github.com/zalandoresearch/fashion-mnist\n"
      ],
      "metadata": {
        "id": "L3SbXD6GU8NX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sulShD5y4K7V"
      },
      "source": [
        "# Treinamento com interface de alto nível"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mALEfpx54K7d"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOn4IXXnGRBg"
      },
      "outputs": [],
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN69WSbu4K7f"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T8iS1Jc4K7q"
      },
      "source": [
        "## Criação da rede"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUi00oew4K7q"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10) # aumento do numero de camadas e de reuronios da NN\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)  # usar mais uma função de ativação tipo ReLU\n",
        "        x = self.fc3(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "model = Net() # usar uma função de ativação tipo ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "400Lbat24K7v"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cqllMDO4K7y"
      },
      "source": [
        "### Criando o objeto de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAEOQoZy4K72"
      },
      "outputs": [],
      "source": [
        "def train(log_interval, dry_run, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            if dry_run:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE6DjiKK4K76"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxdm4FTK4K8E"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cálculo da média e Desvio padrão do dataset FashionMNIST\n",
        "\n",
        "def mean_std(dataset):\n",
        "    # Inicializar variáveis para acumular os valores dos pixels e o número total de pixels\n",
        "    mean = 0.0\n",
        "    std = 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    # Iterar pelo dataset para calcular a média\n",
        "    for data in dataset:\n",
        "        image = data[0]\n",
        "        mean += image.mean()\n",
        "        num_samples += 1\n",
        "\n",
        "    mean /= num_samples\n",
        "\n",
        "    # Iterar pelo dataset novamente para calcular o desvio padrão\n",
        "    for data in dataset:\n",
        "        image = data[0]\n",
        "        std += ((image - mean) ** 2).sum()\n",
        "\n",
        "    std = torch.sqrt(std / (num_samples * 28 * 28))\n",
        "\n",
        "    return mean, std\n",
        "\n"
      ],
      "metadata": {
        "id": "E0QGptEAJy_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgH7e25qb_-K",
        "outputId": "77ed1a00-e6a2-4f9b-c1b8-3e3e5274d7a0",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304282\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.139085\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.862778\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.730511\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.630469\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.569035\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.589158\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.667872\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.490683\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.665207\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.474461\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.588753\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.483361\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.364495\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.460904\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.514643\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.402487\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.494005\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.567753\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.355975\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.361486\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.404603\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.482898\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.417431\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.472055\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.409658\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.361410\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.548152\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.368883\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.364583\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.513681\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.461042\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.425386\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.388289\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.380466\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.272563\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.344280\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.248434\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.396407\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.485929\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.350081\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.400469\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.326150\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.369245\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.300282\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.299924\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.365340\n",
            "\n",
            "Test set: Average loss: 0.3151, Accuracy: 8866/10000 (89%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.257911\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.361881\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.245867\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.245931\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.426480\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.386587\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.359682\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.353332\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.298023\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.362379\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.341369\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.458788\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.444414\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.273406\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.365100\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.563716\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.398090\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.246903\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.202479\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.297710\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.268052\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.245891\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.266935\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.630655\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.314843\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.235005\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.285177\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.270551\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.386661\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.347219\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.275243\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.402831\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.362841\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.349276\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.265097\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.271310\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.287173\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.264463\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.292945\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.302723\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.328841\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.355832\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.201432\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.331257\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.277499\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.320197\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.224103\n",
            "\n",
            "Test set: Average loss: 0.2676, Accuracy: 9032/10000 (90%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.270628\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.264783\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.322418\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.275971\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.325982\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.232263\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.304367\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.222556\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.217560\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.250608\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.254789\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.396250\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.246910\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.327337\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.207115\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.286405\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.303789\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.203296\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.270247\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.191154\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.230759\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.243565\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.397883\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.301159\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.346380\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.194820\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.315490\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.204887\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.181538\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.243169\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.267721\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.228071\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.451824\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.233413\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.266286\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.176773\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.235043\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.172114\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.297446\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.246001\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.185526\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.283884\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.273309\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.223789\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.302539\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.261638\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.215724\n",
            "\n",
            "Test set: Average loss: 0.2416, Accuracy: 9114/10000 (91%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.203829\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.288657\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.212054\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.184710\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.177573\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.270819\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.178113\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.162756\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.196490\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.161986\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.239929\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.285826\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.220451\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.295896\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.269030\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.155544\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.368519\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.201504\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.124477\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.257918\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.177511\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.292187\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.253349\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.239611\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.224901\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.186257\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.166479\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.154229\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.206301\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.317990\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.205596\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.155611\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.185375\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.259073\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.356571\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.236664\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.238797\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.309774\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.243122\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.214306\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.137005\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.180371\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.237258\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.197837\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.268162\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.293249\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.141295\n",
            "\n",
            "Test set: Average loss: 0.2300, Accuracy: 9185/10000 (92%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.231809\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.230342\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.129780\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.164390\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.237310\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.244162\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.212318\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.240006\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.249011\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.208323\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.261089\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.157782\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.229324\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.175053\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.153556\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.157676\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.113868\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.175429\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.250551\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.202074\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.194161\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.225953\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.244902\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.174631\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.223489\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.153943\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.225264\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.233639\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.187862\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.258733\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.189571\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.167230\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.148466\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.248704\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.306244\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.088272\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.204029\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.288402\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.181521\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.200840\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.120223\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.174930\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.116744\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.118120\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.232508\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.152497\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.210375\n",
            "\n",
            "Test set: Average loss: 0.2189, Accuracy: 9199/10000 (92%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.127347\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.162398\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.215749\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.225362\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.119715\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.232870\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.191569\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.123933\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.173474\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.125385\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.170570\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.231087\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.176598\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.115083\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.113802\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.108474\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.270072\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.148660\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.154988\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.112401\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.178529\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.094490\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.125597\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.116594\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.114770\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.142082\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.186403\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.133322\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.171104\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.086709\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.219902\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.139708\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.110326\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.168867\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.128501\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.101249\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.125157\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.211018\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.235844\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.115373\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.166981\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.126663\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.123057\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.103125\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.068595\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.109173\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.152292\n",
            "\n",
            "Test set: Average loss: 0.2036, Accuracy: 9285/10000 (93%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.093351\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.198540\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.128498\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.171717\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.101024\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.145178\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.218385\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.116092\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.071450\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.107932\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.117972\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.152440\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.159027\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.142235\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.089333\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.131770\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.128393\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.131941\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.096189\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.202317\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.161082\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.209822\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.211297\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.134102\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.121444\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.220812\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.170515\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.166855\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.091722\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.130797\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.200573\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.090414\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.122907\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.147431\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.096677\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.130215\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.120447\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.169032\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.106804\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.084848\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.107161\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.103466\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.220934\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.183540\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.130531\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.106594\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.102298\n",
            "\n",
            "Test set: Average loss: 0.2032, Accuracy: 9305/10000 (93%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.103590\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.102737\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.187597\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.104688\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.109191\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.179051\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.080162\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.091758\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.114428\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.126646\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.169191\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.121004\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.157733\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.168989\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.201720\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.077390\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.147581\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.158048\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.146391\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.116319\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.116862\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.073783\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.092160\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.140336\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.118390\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.184151\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.247918\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.073577\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.099197\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.150170\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.241612\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.235814\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.206500\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.149157\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.104831\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.199749\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.164086\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.151860\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.158941\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.140379\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.111212\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.167046\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.135733\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.176350\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.137013\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.143057\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.129432\n",
            "\n",
            "Test set: Average loss: 0.2025, Accuracy: 9305/10000 (93%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.135848\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.137019\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.123109\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.180385\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.097740\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.060246\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.086705\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.107548\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.210419\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.171172\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.151386\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.116446\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.132952\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.141740\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.130530\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.119372\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.234637\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.132022\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.177552\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.087348\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.136673\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.142534\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.139102\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.150552\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.136339\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.085797\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.048459\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.186105\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.192505\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.115660\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.225778\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.155201\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.075100\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.100665\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.149746\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.085812\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.095672\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.124865\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.116128\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.129468\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.152470\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.101937\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.095066\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.075866\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.186515\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.131552\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.101423\n",
            "\n",
            "Test set: Average loss: 0.2033, Accuracy: 9302/10000 (93%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.099248\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.094211\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.139653\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.182643\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.060241\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.075039\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.158734\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.077571\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.088939\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.147484\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.198632\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.177839\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.113020\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.137720\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.088181\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.256906\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.182469\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.101021\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.136713\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.066589\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.139510\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.118042\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.096882\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.109098\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.076334\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.118532\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.151874\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.052466\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.103697\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.117646\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.172108\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.110540\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.108109\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.162128\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.060369\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.121011\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.158199\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.219584\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.110520\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.080811\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.093612\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.100894\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.085299\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.160766\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.168799\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.167300\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.176143\n",
            "\n",
            "Test set: Average loss: 0.2058, Accuracy: 9299/10000 (93%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.112703\n",
            "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.068222\n",
            "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.150823\n",
            "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.087543\n",
            "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.132262\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.179722\n",
            "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.107882\n",
            "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.128598\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.081937\n",
            "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.195509\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.101981\n",
            "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.104560\n",
            "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.172267\n",
            "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.104192\n",
            "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.099623\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.102614\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.197300\n",
            "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.080641\n",
            "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.187829\n",
            "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.088609\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.156904\n",
            "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.129482\n",
            "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.092110\n",
            "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.075992\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.161318\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.126762\n",
            "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.107920\n",
            "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.160008\n",
            "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.130508\n",
            "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.148940\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.134321\n",
            "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.184652\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.112004\n",
            "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.075014\n",
            "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.159511\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.176411\n",
            "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.125830\n",
            "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.083423\n",
            "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.079538\n",
            "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.166290\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.190147\n",
            "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.161957\n",
            "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.227154\n",
            "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.097213\n",
            "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.118542\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.135073\n",
            "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.077885\n",
            "\n",
            "Test set: Average loss: 0.2039, Accuracy: 9323/10000 (93%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.129732\n",
            "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.109013\n",
            "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.137383\n",
            "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.099375\n",
            "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.093329\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.139636\n",
            "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.163091\n",
            "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.092075\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.212872\n",
            "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.120066\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.148872\n",
            "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.118495\n",
            "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.136596\n",
            "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.103593\n",
            "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.082182\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.102741\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.089217\n",
            "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.084093\n",
            "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.192880\n",
            "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.088954\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.084807\n",
            "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.061715\n",
            "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.257786\n",
            "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.083172\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.085426\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.101322\n",
            "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.148319\n",
            "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.077949\n",
            "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.095465\n",
            "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.063048\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.187609\n",
            "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.090228\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.140654\n",
            "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.143914\n",
            "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.125520\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.097315\n",
            "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.093539\n",
            "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.141870\n",
            "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.082085\n",
            "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.139714\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.093272\n",
            "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.115879\n",
            "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.130239\n",
            "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.124084\n",
            "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.116500\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.068158\n",
            "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.173027\n",
            "\n",
            "Test set: Average loss: 0.2041, Accuracy: 9326/10000 (93%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.118312\n",
            "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.103812\n",
            "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.103124\n",
            "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.125617\n",
            "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.157628\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.117400\n",
            "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.112906\n",
            "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.126483\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.095966\n",
            "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.148086\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.075188\n",
            "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.096915\n",
            "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.081730\n",
            "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.152145\n",
            "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.159751\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.076097\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.094944\n",
            "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.146772\n",
            "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.090728\n",
            "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.111751\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.127224\n",
            "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.177827\n",
            "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.146444\n",
            "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.089163\n",
            "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.094009\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.085344\n",
            "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.158860\n",
            "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.158044\n",
            "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.150011\n",
            "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.147271\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.097830\n",
            "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.126211\n",
            "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.173835\n",
            "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.134473\n",
            "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.100135\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.134274\n",
            "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.173495\n",
            "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.065693\n",
            "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.123952\n",
            "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.110774\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.152162\n",
            "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.088118\n",
            "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.137474\n",
            "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.135593\n",
            "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.079046\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.076058\n",
            "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.072100\n",
            "\n",
            "Test set: Average loss: 0.2047, Accuracy: 9323/10000 (93%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.088916\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.165527\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.099216\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.067485\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.169558\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.139620\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.126602\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.078831\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.068529\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.062530\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.167647\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.069121\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.227031\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.122458\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.144431\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.103785\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.156505\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.085823\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.079027\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.115845\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.134509\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.066870\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.108445\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.098962\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.066389\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.170677\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.175770\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.058350\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.100446\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.136701\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.152140\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.079406\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.100994\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.127261\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.084083\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.074849\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.093316\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.090989\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.148850\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.159803\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.190259\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.098966\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.055639\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.125260\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.088276\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.100265\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.093363\n",
            "\n",
            "Test set: Average loss: 0.2050, Accuracy: 9328/10000 (93%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.114094\n",
            "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 0.136473\n",
            "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 0.139792\n",
            "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 0.107826\n",
            "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 0.213932\n",
            "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.079494\n",
            "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 0.079749\n",
            "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 0.060261\n",
            "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.105870\n",
            "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 0.155818\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.085553\n",
            "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 0.116308\n",
            "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 0.165666\n",
            "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 0.137503\n",
            "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 0.107313\n",
            "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.115569\n",
            "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.124263\n",
            "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 0.160267\n",
            "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.084934\n",
            "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 0.062705\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.110858\n",
            "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 0.087221\n",
            "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 0.066176\n",
            "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 0.238749\n",
            "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.058837\n",
            "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.129584\n",
            "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 0.145015\n",
            "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 0.159504\n",
            "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 0.119828\n",
            "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 0.153782\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.134248\n",
            "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 0.091872\n",
            "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.072474\n",
            "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 0.141335\n",
            "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 0.218720\n",
            "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.101299\n",
            "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 0.084792\n",
            "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 0.157487\n",
            "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 0.130168\n",
            "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 0.117604\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.060002\n",
            "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 0.071025\n",
            "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 0.092054\n",
            "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 0.105598\n",
            "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 0.130760\n",
            "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.042627\n",
            "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 0.116813\n",
            "\n",
            "Test set: Average loss: 0.2043, Accuracy: 9327/10000 (93%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.089961\n",
            "Train Epoch: 16 [1280/60000 (2%)]\tLoss: 0.082037\n",
            "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 0.094353\n",
            "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 0.111703\n",
            "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 0.072287\n",
            "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.103450\n",
            "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 0.078868\n",
            "Train Epoch: 16 [8960/60000 (15%)]\tLoss: 0.100039\n",
            "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.117643\n",
            "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 0.058227\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.061850\n",
            "Train Epoch: 16 [14080/60000 (23%)]\tLoss: 0.133165\n",
            "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 0.159061\n",
            "Train Epoch: 16 [16640/60000 (28%)]\tLoss: 0.210923\n",
            "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 0.147407\n",
            "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.102094\n",
            "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.155155\n",
            "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 0.080284\n",
            "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 0.067986\n",
            "Train Epoch: 16 [24320/60000 (41%)]\tLoss: 0.161840\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.073656\n",
            "Train Epoch: 16 [26880/60000 (45%)]\tLoss: 0.050323\n",
            "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 0.142287\n",
            "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 0.083631\n",
            "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.236235\n",
            "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.167953\n",
            "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 0.096130\n",
            "Train Epoch: 16 [34560/60000 (58%)]\tLoss: 0.154055\n",
            "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 0.139803\n",
            "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 0.098361\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.137354\n",
            "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 0.096056\n",
            "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.124570\n",
            "Train Epoch: 16 [42240/60000 (70%)]\tLoss: 0.124717\n",
            "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 0.087042\n",
            "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.050859\n",
            "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 0.137959\n",
            "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 0.115612\n",
            "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 0.127512\n",
            "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 0.037678\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.134631\n",
            "Train Epoch: 16 [52480/60000 (87%)]\tLoss: 0.110064\n",
            "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 0.126431\n",
            "Train Epoch: 16 [55040/60000 (92%)]\tLoss: 0.106735\n",
            "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 0.107468\n",
            "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.159538\n",
            "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 0.099343\n",
            "\n",
            "Test set: Average loss: 0.2044, Accuracy: 9327/10000 (93%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.120438\n",
            "Train Epoch: 17 [1280/60000 (2%)]\tLoss: 0.085583\n",
            "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 0.141723\n",
            "Train Epoch: 17 [3840/60000 (6%)]\tLoss: 0.137233\n",
            "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 0.099046\n",
            "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.070999\n",
            "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 0.112963\n",
            "Train Epoch: 17 [8960/60000 (15%)]\tLoss: 0.130401\n",
            "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.094382\n",
            "Train Epoch: 17 [11520/60000 (19%)]\tLoss: 0.117882\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.151187\n",
            "Train Epoch: 17 [14080/60000 (23%)]\tLoss: 0.116452\n",
            "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 0.108735\n",
            "Train Epoch: 17 [16640/60000 (28%)]\tLoss: 0.118022\n",
            "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 0.095465\n",
            "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.117630\n",
            "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.054997\n",
            "Train Epoch: 17 [21760/60000 (36%)]\tLoss: 0.043579\n",
            "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 0.177744\n",
            "Train Epoch: 17 [24320/60000 (41%)]\tLoss: 0.096081\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.119881\n",
            "Train Epoch: 17 [26880/60000 (45%)]\tLoss: 0.088559\n",
            "Train Epoch: 17 [28160/60000 (47%)]\tLoss: 0.118099\n",
            "Train Epoch: 17 [29440/60000 (49%)]\tLoss: 0.054954\n",
            "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.134228\n",
            "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.088992\n",
            "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 0.086974\n",
            "Train Epoch: 17 [34560/60000 (58%)]\tLoss: 0.051856\n",
            "Train Epoch: 17 [35840/60000 (60%)]\tLoss: 0.077422\n",
            "Train Epoch: 17 [37120/60000 (62%)]\tLoss: 0.133017\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.171422\n",
            "Train Epoch: 17 [39680/60000 (66%)]\tLoss: 0.062780\n",
            "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.090827\n",
            "Train Epoch: 17 [42240/60000 (70%)]\tLoss: 0.105072\n",
            "Train Epoch: 17 [43520/60000 (72%)]\tLoss: 0.124663\n",
            "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.090995\n",
            "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 0.121314\n",
            "Train Epoch: 17 [47360/60000 (79%)]\tLoss: 0.080822\n",
            "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 0.188155\n",
            "Train Epoch: 17 [49920/60000 (83%)]\tLoss: 0.122120\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.149715\n",
            "Train Epoch: 17 [52480/60000 (87%)]\tLoss: 0.182597\n",
            "Train Epoch: 17 [53760/60000 (90%)]\tLoss: 0.099588\n",
            "Train Epoch: 17 [55040/60000 (92%)]\tLoss: 0.135174\n",
            "Train Epoch: 17 [56320/60000 (94%)]\tLoss: 0.134595\n",
            "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.114263\n",
            "Train Epoch: 17 [58880/60000 (98%)]\tLoss: 0.055873\n",
            "\n",
            "Test set: Average loss: 0.2044, Accuracy: 9328/10000 (93%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.128872\n",
            "Train Epoch: 18 [1280/60000 (2%)]\tLoss: 0.142211\n",
            "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 0.202072\n",
            "Train Epoch: 18 [3840/60000 (6%)]\tLoss: 0.091976\n",
            "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 0.060819\n",
            "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.096572\n",
            "Train Epoch: 18 [7680/60000 (13%)]\tLoss: 0.077087\n",
            "Train Epoch: 18 [8960/60000 (15%)]\tLoss: 0.098221\n",
            "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.110371\n",
            "Train Epoch: 18 [11520/60000 (19%)]\tLoss: 0.107487\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.151631\n",
            "Train Epoch: 18 [14080/60000 (23%)]\tLoss: 0.096243\n",
            "Train Epoch: 18 [15360/60000 (26%)]\tLoss: 0.087469\n",
            "Train Epoch: 18 [16640/60000 (28%)]\tLoss: 0.161684\n",
            "Train Epoch: 18 [17920/60000 (30%)]\tLoss: 0.097466\n",
            "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.177301\n",
            "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.137174\n",
            "Train Epoch: 18 [21760/60000 (36%)]\tLoss: 0.112974\n",
            "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 0.137192\n",
            "Train Epoch: 18 [24320/60000 (41%)]\tLoss: 0.202743\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.087818\n",
            "Train Epoch: 18 [26880/60000 (45%)]\tLoss: 0.166668\n",
            "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 0.128697\n",
            "Train Epoch: 18 [29440/60000 (49%)]\tLoss: 0.113599\n",
            "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.112508\n",
            "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.157183\n",
            "Train Epoch: 18 [33280/60000 (55%)]\tLoss: 0.183929\n",
            "Train Epoch: 18 [34560/60000 (58%)]\tLoss: 0.123731\n",
            "Train Epoch: 18 [35840/60000 (60%)]\tLoss: 0.116411\n",
            "Train Epoch: 18 [37120/60000 (62%)]\tLoss: 0.101454\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.146570\n",
            "Train Epoch: 18 [39680/60000 (66%)]\tLoss: 0.169921\n",
            "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.202318\n",
            "Train Epoch: 18 [42240/60000 (70%)]\tLoss: 0.091265\n",
            "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 0.140492\n",
            "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.128481\n",
            "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 0.082402\n",
            "Train Epoch: 18 [47360/60000 (79%)]\tLoss: 0.128099\n",
            "Train Epoch: 18 [48640/60000 (81%)]\tLoss: 0.175486\n",
            "Train Epoch: 18 [49920/60000 (83%)]\tLoss: 0.114916\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.143296\n",
            "Train Epoch: 18 [52480/60000 (87%)]\tLoss: 0.129700\n",
            "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 0.056190\n",
            "Train Epoch: 18 [55040/60000 (92%)]\tLoss: 0.143959\n",
            "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 0.105889\n",
            "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.087709\n",
            "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 0.111179\n",
            "\n",
            "Test set: Average loss: 0.2045, Accuracy: 9330/10000 (93%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.123758\n",
            "Train Epoch: 19 [1280/60000 (2%)]\tLoss: 0.130193\n",
            "Train Epoch: 19 [2560/60000 (4%)]\tLoss: 0.086455\n",
            "Train Epoch: 19 [3840/60000 (6%)]\tLoss: 0.113358\n",
            "Train Epoch: 19 [5120/60000 (9%)]\tLoss: 0.082474\n",
            "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.162001\n",
            "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 0.071674\n",
            "Train Epoch: 19 [8960/60000 (15%)]\tLoss: 0.045380\n",
            "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.168598\n",
            "Train Epoch: 19 [11520/60000 (19%)]\tLoss: 0.072092\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.099947\n",
            "Train Epoch: 19 [14080/60000 (23%)]\tLoss: 0.149870\n",
            "Train Epoch: 19 [15360/60000 (26%)]\tLoss: 0.088003\n",
            "Train Epoch: 19 [16640/60000 (28%)]\tLoss: 0.074330\n",
            "Train Epoch: 19 [17920/60000 (30%)]\tLoss: 0.125288\n",
            "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.159443\n",
            "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.122232\n",
            "Train Epoch: 19 [21760/60000 (36%)]\tLoss: 0.176327\n",
            "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 0.069108\n",
            "Train Epoch: 19 [24320/60000 (41%)]\tLoss: 0.099340\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.097799\n",
            "Train Epoch: 19 [26880/60000 (45%)]\tLoss: 0.057633\n",
            "Train Epoch: 19 [28160/60000 (47%)]\tLoss: 0.095203\n",
            "Train Epoch: 19 [29440/60000 (49%)]\tLoss: 0.133161\n",
            "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.076207\n",
            "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.095585\n",
            "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 0.129160\n",
            "Train Epoch: 19 [34560/60000 (58%)]\tLoss: 0.116992\n",
            "Train Epoch: 19 [35840/60000 (60%)]\tLoss: 0.103477\n",
            "Train Epoch: 19 [37120/60000 (62%)]\tLoss: 0.149280\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.077113\n",
            "Train Epoch: 19 [39680/60000 (66%)]\tLoss: 0.124032\n",
            "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.143122\n",
            "Train Epoch: 19 [42240/60000 (70%)]\tLoss: 0.148423\n",
            "Train Epoch: 19 [43520/60000 (72%)]\tLoss: 0.067900\n",
            "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.080774\n",
            "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 0.112480\n",
            "Train Epoch: 19 [47360/60000 (79%)]\tLoss: 0.135494\n",
            "Train Epoch: 19 [48640/60000 (81%)]\tLoss: 0.070875\n",
            "Train Epoch: 19 [49920/60000 (83%)]\tLoss: 0.088158\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.132244\n",
            "Train Epoch: 19 [52480/60000 (87%)]\tLoss: 0.141897\n",
            "Train Epoch: 19 [53760/60000 (90%)]\tLoss: 0.055648\n",
            "Train Epoch: 19 [55040/60000 (92%)]\tLoss: 0.130589\n",
            "Train Epoch: 19 [56320/60000 (94%)]\tLoss: 0.089138\n",
            "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.110107\n",
            "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 0.118559\n",
            "\n",
            "Test set: Average loss: 0.2045, Accuracy: 9330/10000 (93%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.138497\n",
            "Train Epoch: 20 [1280/60000 (2%)]\tLoss: 0.072509\n",
            "Train Epoch: 20 [2560/60000 (4%)]\tLoss: 0.175498\n",
            "Train Epoch: 20 [3840/60000 (6%)]\tLoss: 0.091211\n",
            "Train Epoch: 20 [5120/60000 (9%)]\tLoss: 0.106617\n",
            "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.116508\n",
            "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 0.199318\n",
            "Train Epoch: 20 [8960/60000 (15%)]\tLoss: 0.109802\n",
            "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.136926\n",
            "Train Epoch: 20 [11520/60000 (19%)]\tLoss: 0.087411\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.120084\n",
            "Train Epoch: 20 [14080/60000 (23%)]\tLoss: 0.102580\n",
            "Train Epoch: 20 [15360/60000 (26%)]\tLoss: 0.077027\n",
            "Train Epoch: 20 [16640/60000 (28%)]\tLoss: 0.118944\n",
            "Train Epoch: 20 [17920/60000 (30%)]\tLoss: 0.136765\n",
            "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.230364\n",
            "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.101584\n",
            "Train Epoch: 20 [21760/60000 (36%)]\tLoss: 0.060700\n",
            "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 0.104717\n",
            "Train Epoch: 20 [24320/60000 (41%)]\tLoss: 0.136392\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.146299\n",
            "Train Epoch: 20 [26880/60000 (45%)]\tLoss: 0.127751\n",
            "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 0.052819\n",
            "Train Epoch: 20 [29440/60000 (49%)]\tLoss: 0.116894\n",
            "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.161380\n",
            "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.097862\n",
            "Train Epoch: 20 [33280/60000 (55%)]\tLoss: 0.143318\n",
            "Train Epoch: 20 [34560/60000 (58%)]\tLoss: 0.178311\n",
            "Train Epoch: 20 [35840/60000 (60%)]\tLoss: 0.098162\n",
            "Train Epoch: 20 [37120/60000 (62%)]\tLoss: 0.120716\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.114411\n",
            "Train Epoch: 20 [39680/60000 (66%)]\tLoss: 0.106894\n",
            "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.079050\n",
            "Train Epoch: 20 [42240/60000 (70%)]\tLoss: 0.103218\n",
            "Train Epoch: 20 [43520/60000 (72%)]\tLoss: 0.083294\n",
            "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.118717\n",
            "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 0.091418\n",
            "Train Epoch: 20 [47360/60000 (79%)]\tLoss: 0.173677\n",
            "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 0.143935\n",
            "Train Epoch: 20 [49920/60000 (83%)]\tLoss: 0.097604\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.145360\n",
            "Train Epoch: 20 [52480/60000 (87%)]\tLoss: 0.074229\n",
            "Train Epoch: 20 [53760/60000 (90%)]\tLoss: 0.110855\n",
            "Train Epoch: 20 [55040/60000 (92%)]\tLoss: 0.197633\n",
            "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 0.095003\n",
            "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.149853\n",
            "Train Epoch: 20 [58880/60000 (98%)]\tLoss: 0.084250\n",
            "\n",
            "Test set: Average loss: 0.2045, Accuracy: 9329/10000 (93%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(1111)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_kwargs = {'batch_size': 128} # aumento do tamanho dos batches de treino\n",
        "test_kwargs = {'batch_size': 1000}\n",
        "if use_cuda:\n",
        "    cuda_kwargs = {'num_workers': 1,\n",
        "                    'pin_memory': True,\n",
        "                    'shuffle': True}\n",
        "    train_kwargs.update(cuda_kwargs)\n",
        "    test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "mean, std = mean_std(datasets.FashionMNIST(\n",
        "    root='../data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")) # calculo de mean e std do dataset FashionMNIST sem tratamento\n",
        "\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((mean,), (std,))\n",
        "    ])\n",
        "# dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "#                    transform=transform)\n",
        "# dataset2 = datasets.MNIST('../data', train=False,\n",
        "#                    transform=transform)\n",
        "# train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "# test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "# Load a different dataset\n",
        "# new_dataset = datasets.FashionMNIST('../data', download=True, train=True, transform=transform)\n",
        "train_dataset = datasets.FashionMNIST('../data', download=True, train=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST('../data', download=True, train=False, transform=transform)\n",
        "\n",
        "# Create a new data loader for the new dataset\n",
        "new_train_loader = torch.utils.data.DataLoader(train_dataset, **train_kwargs)\n",
        "new_test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.01) # mudança do optmizador e diminuição do Learning rate\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # mudança do optmizador e diminuição do Learning rate\n",
        "\n",
        "epochs = 20 # aumento do numero de épocas\n",
        "# scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) # mudança do scheduler\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(10, False, model, device, new_train_loader, optimizer, epoch)\n",
        "    test(model, device, new_test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O PROCESSO E A EXPERIÊNCIA:\n",
        "\n",
        "## (i) Carregamento do Dataset e Manipulação de Dados\n",
        "\n",
        "- O dataset escolhido foi o FashionMNIST e os dados foram carregados a partir de [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist).\n",
        "\n",
        "- A manipulação dos dados consistiu em:\n",
        "\n",
        "  1. Transformar as imagens do dataset em tensores.\n",
        "  2. Calcular a média e o desvio padrão do dataset.\n",
        "  3. Normalizar as imagens usando a média e o desvio padrão dos dados.\n",
        "\n",
        "## (ii) Definição do Modelo da Rede\n",
        "\n",
        "- Modelo de rede neural, baseado no colab da atividade da aula 4.6 MNIST_neuralnet da disciplina Redes Neurais e Deep Learning ministrada pelo Prof. Victor Casadei: uma rede convolucional composta por duas camadas convolucionais seguidas de pooling e dropout, e três camadas totalmente conectadas com dropout entre a primeira e a segunda.\n",
        "- Função de ativação: ReLU usada para introduzir não-linearidade.\n",
        "- Saída: distribuição de probabilidade logarítmica sobre as 10 classes, obtida usando log-softmax.\n",
        "\n",
        "- Fluxo de Dados:\n",
        "  1. Entrada -> conv1 -> ReLU -> conv2 -> ReLU -> max_pool2d -> dropout1 -> flatten.\n",
        "  2. Flatten -> fc1 -> ReLU -> dropout2 -> fc2 -> ReLU -> fc3.\n",
        "  3. fc3 -> Log-Softmax -> Saída.\n",
        "\n",
        "- O modelo se propõe a, dada uma imagem do tipo MNIST de itens de vestuário, classificá-la nas seguintes categorias:\n",
        "\n",
        "  1. T-shirt/top (Camiseta/top)\n",
        "  2. Trouser (Calça)\n",
        "  3. Pullover (Pulôver)\n",
        "  4. Dress (Vestido)\n",
        "  5. Coat (Casaco)\n",
        "  6. Sandal (Sandália)\n",
        "  7. Shirt (Camisa)\n",
        "  8. Sneaker (Tênis)\n",
        "  9. Bag (Bolsa)\n",
        "  10. Ankle boot (Bota)\n",
        "\n",
        "## (iii) Treinamento do Modelo\n",
        "\n",
        "### Mudanças Realizadas no Código\n",
        "\n",
        "Melhorias foram feitas para aumentar a precisão do modelo e evitar o overfitting. O aumento do número de camadas e de neurônios da rede neural permitiu que o modelo aprendesse características mais complexas dos dados. A utilização de mais uma função de ativação tipo ReLU também ajudou a evitar o overfitting. O aumento do tamanho dos batches de treino fez com que o modelo fosse atualizado com mais dados a cada iteração, o que também ajudou a evitar o overfitting. A mudança do otimizador para Adam com uma taxa de aprendizado menor permitiu que o modelo convergisse mais rapidamente para uma solução ótima. O aumento do número de épocas propiciou ao modelo mais tempo para aprender com os dados de treino. A mudança do scheduler para StepLR com um fator de decaimento menor permitiu que a taxa de aprendizado fosse reduzida gradualmente ao longo do treinamento, o que também ajuda a evitar o overfitting. Em resumo, as melhorias foram:\n",
        "\n",
        "- Aumento do número de camadas e de neurônios da rede neural.\n",
        "- Utilização de mais uma função de ativação tipo ReLU.\n",
        "- Aumento do tamanho dos batches de treino.\n",
        "- Mudança do otimizador para Adam com uma taxa de aprendizado menor.\n",
        "- Aumento do número de épocas.\n",
        "- Mudança do scheduler para StepLR com um fator de decaimento menor.\n",
        "\n",
        "# (iv) Acurácia do Modelo Treinado\n",
        "\n",
        "- O modelo obteve uma acurácia de 93% no conjunto de teste. Isso significa que o modelo foi capaz de classificar corretamente 93% das imagens do conjunto de teste.\n",
        "- A perda média no conjunto de teste foi de 0.2045. Isso significa que o modelo, em média, cometeu um erro de classificação de 0.2045 para cada imagem do conjunto de teste.\n",
        "- Esses resultados já são bons, mas podem ser melhorados, por exemplo, treinando o modelo por mais épocas e/ou usando um otimizador diferente e/ou utilizando uma arquitetura de rede diferente.\n",
        "- No geral, o modelo obteve um bom desempenho no conjunto de teste, o que indica que ele é capaz de classificar corretamente imagens do dataset FashionMNIST.\n",
        "\n",
        "# CONCLUSÕES:\n",
        "A implementação da rede neural para o dataset FashionMNIST demonstraram resultados promissores, com uma acurácia de 93% no conjunto de teste.\n",
        "As melhorias realizadas, como o aumento do número de camadas e neurônios, a utilização de funções de ativação adicionais, a mudança do otimizador para Adam e ajustes no scheduler, foram fundamentais para alcançar este nível de precisão, além de mitigar o overfitting.\n",
        "A capacidade do modelo de aprender características complexas dos dados foi aumentada, e a utilização de estratégias de regularização adicionais contribuiu para a estabilidade e eficácia do treinamento.\n",
        "Embora o desempenho obtido seja significativo, existem oportunidades para aprimoramento, como o ajuste de hiperparâmetros e a exploração de arquiteturas de rede ainda mais complexas.\n",
        "No geral, a rede desenvolvida mostra-se competente para a tarefa de classificação de itens de vestuário, destacando a importância de técnicas avançadas de treinamento e ajustes finos na obtenção de modelos robustos e precisos.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XOdMrpstAVeA"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "5fe3e6f0cdaab8afdc61c52912fda83f7c0a71baaea1897dd7498e2df01e69ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}